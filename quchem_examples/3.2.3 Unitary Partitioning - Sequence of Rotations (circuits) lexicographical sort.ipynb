{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### open Hamiltonian data ###\n",
    "\n",
    "working_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(working_dir) # gets directory where running python file is!\n",
    "\n",
    "data_dir = os.path.join(parent_dir, 'Molecular_Hamiltonian_data')\n",
    "hamiltonian_data = os.path.join(data_dir, 'hamiltonians.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hamiltonian_data, 'r') as input_file:\n",
    "    hamiltonians = ast.literal_eval(input_file.read())\n",
    "\n",
    "for key in hamiltonians.keys():\n",
    "    print(f\"{key: <25}     n_qubits:  {hamiltonians[key][1]:<5.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# molecule_key = 'H1-Li1-O1_STO-3G_singlet'\n",
    "molecule_key = 'H2_6-31G_singlet'\n",
    "# molecule_key = 'H1-He1_3-21G_singlet_1+'\n",
    "transformation, N_qubits, Hamilt_dictionary, _ ,_, _ = hamiltonians[molecule_key]\n",
    "del hamiltonians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get OpenFermion representation of Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Misc_functions.conversion_scripts import Get_Openfermion_Hamiltonian\n",
    "\n",
    "openFermion_H = Get_Openfermion_Hamiltonian(Hamilt_dictionary)\n",
    "openFermion_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get cliques defined by commutativity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Graph import Clique_cover_Hamiltonian\n",
    "\n",
    "commutativity_flag = 'AC' ## <- defines relationship between sets!!!\n",
    "Graph_colouring_strategy='largest_first'\n",
    "\n",
    "\n",
    "anti_commuting_sets = Clique_cover_Hamiltonian(openFermion_H, \n",
    "                                                     N_qubits, \n",
    "                                                     commutativity_flag, \n",
    "                                                     Graph_colouring_strategy)\n",
    "anti_commuting_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Example of X_sk operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lexicographica order\n",
    "(maximises circuit reductions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_larg, largest_AC_set = max(anti_commuting_sets.items(), key=lambda x:len(x[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_AC_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Seq_Rot_circuit_functions_AUTO import Auto_Build_R_SeqRot_Q_circuit_manual_Reduced\n",
    "\n",
    "full_RS_circuit, Ps, gamma_l = Auto_Build_R_SeqRot_Q_circuit_manual_Reduced(largest_AC_set,\n",
    "                                                      N_qubits, \n",
    "                                                      check_reduction_lin_alg=True, \n",
    "                                                      atol=1e-8, rtol=1e-05, \n",
    "                                                      check_circuit=True, \n",
    "                                                      maximise_CNOT_reduction=True)\n",
    "full_RS_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Seq_Rot_circuit_functions_AUTO import Auto_Build_R_SeqRot_Q_circuit_IBM_Reduced\n",
    "\n",
    "IBM_full_RS_circuit, IBM_Ps, IBM_gamma_l = Auto_Build_R_SeqRot_Q_circuit_IBM_Reduced(largest_AC_set,\n",
    "                                                      N_qubits, \n",
    "                                                      check_reduction_lin_alg=True, \n",
    "                                                      atol=1e-8, rtol=1e-05, \n",
    "                                                      check_circuit=True, \n",
    "                                                      maximise_CNOT_reduction=True)\n",
    "IBM_full_RS_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Misc_functions.Misc_functions import count_circuit_gates\n",
    "print(count_circuit_gates(full_RS_circuit))\n",
    "print(count_circuit_gates(IBM_full_RS_circuit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Misc_functions.Misc_functions import Get_circuit_depth\n",
    "print('quantum circuit depth:', Get_circuit_depth(full_RS_circuit))\n",
    "print('IBM quantum circuit depth:', Get_circuit_depth(IBM_full_RS_circuit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([i**2 for i in range(10)])% 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear algebra expermient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermion.linalg import qubit_operator_sparse\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "H_matrix = qubit_operator_sparse(openFermion_H)\n",
    "eig_values, eig_vectors = eigh(H_matrix.todense()) # NOT sparse!\n",
    "\n",
    "idx = eig_values.argsort()  \n",
    "eigenValues = eig_values[idx]\n",
    "eigenVectors = eig_vectors[:,idx]\n",
    "\n",
    "ground_state = np.around(eigenVectors[:,0].real, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_state.conj().T @ H_matrix.todense() @ ground_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(eigenValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Qcircuit.Circuit_functions_to_create_arb_state import intialization_circuit\n",
    "ansatz_circuit, global_phase = intialization_circuit(ground_state,\n",
    "                             0,\n",
    "                             check_circuit=False)\n",
    "\n",
    "print('global_phase =', global_phase)\n",
    "ansatz_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(ground_state, ansatz_circuit.final_state_vector()*global_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Qcircuit.Circuit_functions_to_create_arb_state import prepare_arb_state_cirq_matrix_gate\n",
    "ansatz_circuit = prepare_arb_state_cirq_matrix_gate(ground_state)\n",
    "ansatz_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(ground_state, ansatz_circuit.final_state_vector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = ansatz_circuit.final_state_vector()\n",
    "np.trace(np.outer(final_state, final_state)@H_matrix)\n",
    "# ansatz_circuit.final_state_vector().conj().T @ H_matrix.todense() @ ansatz_circuit.final_state_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Seq_Rot_circuit_functions_AUTO import Auto_Seq_Rot_VQE_Experiment_UP_manual_reduced_circuit_lin_alg\n",
    "\n",
    "manual_reduction_lin_alg_SeqRot_exp = Auto_Seq_Rot_VQE_Experiment_UP_manual_reduced_circuit_lin_alg(\n",
    "anti_commuting_sets,\n",
    "ansatz_circuit)\n",
    "\n",
    "E_SeqRot_manual_circuit_reduction = manual_reduction_lin_alg_SeqRot_exp.Calc_Energy(check_circuit=True,\n",
    "                                                                                    check_reduction_lin_alg=True, \n",
    "                                                                                    maximise_CNOT_reduction=True)\n",
    "E_SeqRot_manual_circuit_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Seq_Rot_circuit_functions_AUTO import Auto_Seq_Rot_VQE_Experiment_UP_IBM_reduced_circuit_lin_alg\n",
    "\n",
    "IBM_reduction_lin_alg_SeqRot_exp = Auto_Seq_Rot_VQE_Experiment_UP_IBM_reduced_circuit_lin_alg(\n",
    "anti_commuting_sets,\n",
    "ansatz_circuit,\n",
    "allowed_qiskit_gates=['id', 'rz', 'ry', 'rx', 'cx' ,'s', 'h', 'y','z'],\n",
    "IBM_opt_lvl=3)\n",
    "\n",
    "E_SeqRot_IBM_circuit_reduction = IBM_reduction_lin_alg_SeqRot_exp.Calc_Energy(check_circuit=True)\n",
    "E_SeqRot_IBM_circuit_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermion import QubitOperator\n",
    "Ps = QubitOperator('Y1 X2', 0.2)\n",
    "PauliStr_Ps, beta_S = tuple(*Ps.terms.items())\n",
    "PauliStr_Ps_Z = [(qNo, 'Z')for qNo, Pstr in PauliStr_Ps]\n",
    "Ps_Zchange = QubitOperator(PauliStr_Ps_Z, beta_S)\n",
    "Ps_Zchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Seq_Rot_circuit_functions import Seq_Rot_VQE_Experiment_UP_circuit_lin_alg\n",
    "\n",
    "exp_linalg_pure = Seq_Rot_VQE_Experiment_UP_circuit_lin_alg(anti_commuting_sets, ansatz_circuit, S_key_dict=None)\n",
    "exp_linalg_pure.Calc_Energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(eigenValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Seq_Rot_circuit_functions_AUTO import Auto_Build_R_SeqRot_Q_circuit_tiket_Reduced\n",
    "\n",
    "full_RS_circuit_tiket, Ps, gamma_l = Auto_Build_R_SeqRot_Q_circuit_tiket_Reduced(anti_commuting_sets[1],\n",
    "                                                      N_qubits, \n",
    "                                                      check_reduction_lin_alg=True, \n",
    "                                                      atol=1e-8, rtol=1e-05, \n",
    "                                                      check_circuit=True, \n",
    "                                                      maximise_CNOT_reduction=True)\n",
    "full_RS_circuit_tiket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Seq_Rot_circuit_functions_AUTO import Full_SeqRot_auto_Rl_Circuit_tiket_Reduced\n",
    "\n",
    "full_circuit_tiket, Ps, gamma_l = Full_SeqRot_auto_Rl_Circuit_tiket_Reduced(\n",
    "                                                      ansatz_circuit,\n",
    "                                                      anti_commuting_sets[1],\n",
    "                                                      N_qubits, \n",
    "#                                                       check_reduction_lin_alg=True, \n",
    "#                                                       check_circuit=True, \n",
    "                                                      maximise_CNOT_reduction=True)\n",
    "full_circuit_tiket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_RS_circuit_tiket, Ps, gamma_l = Auto_Build_R_SeqRot_Q_circuit_tiket_Reduced(largest_AC_set,\n",
    "                                                      N_qubits, \n",
    "                                                      check_reduction_lin_alg=True, \n",
    "                                                      atol=1e-8, rtol=1e-05, \n",
    "                                                      check_circuit=True, \n",
    "                                                      maximise_CNOT_reduction=True)\n",
    "full_RS_circuit_tiket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Misc_functions.Misc_functions import count_circuit_gates\n",
    "print(count_circuit_gates(full_RS_circuit))\n",
    "print(count_circuit_gates(IBM_full_RS_circuit))\n",
    "print()\n",
    "print(count_circuit_gates(full_RS_circuit_tiket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Seq_Rot_circuit_functions_AUTO import Auto_Seq_Rot_VQE_Experiment_UP_tiket_reduced_circuit_lin_alg\n",
    "\n",
    "exp = Auto_Seq_Rot_VQE_Experiment_UP_tiket_reduced_circuit_lin_alg(anti_commuting_sets, ansatz_circuit)\n",
    "exp.Calc_Energy(check_reduction_lin_alg=True, check_circuit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(eigenValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def lexicographical_sort_BASIS_MATCH(list_P_ops):\n",
    "    \"\"\"\n",
    "    maximises adjacent single qubit pauli terms in Pauliword list (allowing best change of basis cancellation)\n",
    "    \"\"\"\n",
    "    fullOp = reduce(lambda Op1, Op2: Op1+Op2, list_P_ops)\n",
    "    max_qubits = count_qubits(fullOp)\n",
    "\n",
    "    P_Words = []\n",
    "    for op in list_P_ops:\n",
    "        \n",
    "#         Q_Nos, P_strings = zip(*list(*op.terms.keys()))\n",
    "#         P_dict = dict(zip(Q_Nos, P_strings)) # zip(keys, values)\n",
    "\n",
    "        P_dict =  dict(tuple(*op.terms.keys())) \n",
    "        arr = [P_dict.get(qNo, 'I') for qNo in range(max_qubits)]\n",
    "          \n",
    "        P_Words.append(arr)\n",
    "    \n",
    "    P_Words_copy = deepcopy(P_Words)\n",
    "    re_ordered_ind =[]\n",
    "    sorted_list = []\n",
    "    while P_Words!=[]:\n",
    "        if sorted_list==[]:\n",
    "            ind_match=0\n",
    "        else:\n",
    "            op_prev = sorted_list[-1] # take last sorted term\n",
    "            \n",
    "            # get similarity in binary and sum array\n",
    "            # the larger the int the better the match between sigma terms!\n",
    "            similarity_list = [(op_j,sum((np.array(op_prev)==np.array(op_j)).astype(int))) for op_j in P_Words if op_j != op_i]\n",
    "            largest_match = max(similarity_list, key=lambda x:x[1])\n",
    "            ind_similarity_list = similarity_list.index(largest_match)\n",
    "\n",
    "            op_j = similarity_list[ind_similarity_list][0]\n",
    "            ind_match = P_Words.index(op_j)\n",
    "            \n",
    "        op_i = P_Words.pop(ind_match)\n",
    "        sorted_list.append(op_i)\n",
    "        re_ordered_ind.append(P_Words_copy.index(op_i))\n",
    "\n",
    "\n",
    "    lex_sorted = (np.array(list_P_ops)[re_ordered_ind]).tolist()\n",
    "    return lex_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Graph import Vector_QubitHamiltonian\n",
    "from functools import reduce\n",
    "from openfermion.utils import count_qubits\n",
    "\n",
    "list_P_ops = largest_AC_set\n",
    "\n",
    "fullOp = reduce(lambda Op1, Op2: Op1+Op2, list_P_ops)\n",
    "max_qubits = count_qubits(fullOp)\n",
    "\n",
    "Hamilt_vector = Vector_QubitHamiltonian(fullOp, max_qubits)\n",
    "binary_matrix =  Hamilt_vector.binary_mat.toarray()\n",
    "\n",
    "print(binary_matrix)\n",
    "list(fullOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_order = np.zeros_like(binary_matrix)\n",
    "# new_order[0,:] = binary_matrix[0,:]\n",
    "# for ind in range(1,binary_matrix.shape[0]):\n",
    "#     Hamilt_vector.binary_mat[:,ind]\n",
    "\n",
    "new_order = binary_matrix[0].copy().reshape(1, binary_matrix.shape[1])\n",
    "binary_matrix =np.delete(binary_matrix, 0, 0)\n",
    "# while new_order.shape[0]!=len(list_P_ops):\n",
    "while binary_matrix.shape[0]>0:\n",
    "    score_list=[]\n",
    "    for P_vec in binary_matrix:\n",
    "        similarity=0\n",
    "        for rev_ind in list(range(new_order.shape[0]-1, -1, -1)):\n",
    "            P_last = new_order[rev_ind]\n",
    "            similarity += sum((P_vec==P_last).astype(int))\n",
    "            \n",
    "            I_locations = np.intersect1d(np.where(P_last[:max_qubits]==0)[0], np.where(P_last[max_qubits:]==0)[0])\n",
    "            ind_sympletic = np.hstack((I_locations, max_qubits+I_locations))\n",
    "            \n",
    "            empty = np.zeros_like(P_vec)\n",
    "            empty[ind_sympletic] = P_vec[ind_sympletic]\n",
    "            P_vec = empty\n",
    "            \n",
    "        score_list.append(similarity)\n",
    "    \n",
    "    print(score_list)\n",
    "    largest_ind = score_list.index(max(score_list))\n",
    "    new_order = np.vstack((new_order, binary_matrix[largest_ind]))\n",
    "    binary_matrix =np.delete(binary_matrix, largest_ind, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array([1,0,0,0]) + np.array([1,0,0,0]))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for P_symp in new_order:\n",
    "    P_str =''\n",
    "    for i in range(max_qubits):\n",
    "        X_term=P_symp[i]\n",
    "        Z_term=P_symp[i+max_qubits]\n",
    "        \n",
    "        if (X_term+Z_term)==1:\n",
    "            P_str += 'Y'\n",
    "        elif X_term == 1:\n",
    "            P_str += 'X'\n",
    "        elif Z_term == 1:\n",
    "            P_str += 'Z'\n",
    "        else:\n",
    "            P_str += 'I'\n",
    "    print(P_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for P_symp in Hamilt_vector.binary_mat.toarray():\n",
    "    P_str =''\n",
    "    for i in range(max_qubits):\n",
    "        X_term=P_symp[i]\n",
    "        Z_term=P_symp[i+max_qubits]\n",
    "        \n",
    "        if (X_term+Z_term)==1:\n",
    "            P_str += 'Y'\n",
    "        elif X_term == 1:\n",
    "            P_str += 'X'\n",
    "        elif Z_term == 1:\n",
    "            P_str += 'Z'\n",
    "        else:\n",
    "            P_str += 'I'\n",
    "    print(P_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicographical_sort_BASIS_MATCH(largest_AC_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_locations = np.where(P_last[:max_qubits]==P_last[max_qubits:])[0]\n",
    "P_vec[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_last[np.hstack((I_locations, 2*I_locations))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_vec[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.array([1,2,3]), np.array([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_order[0,:]==new_order[1,:]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = binary_matrix[0:2,:]\n",
    "new_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "\n",
    "A = np.delete(A, 2, 0)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in A:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_matrix[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hamilt_vector.binary_mat[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_list = ['XXXI', 'ZIZZ']\n",
    "\n",
    "outer_most_term = \n",
    "\n",
    "[ind for ind, sig in enumerate('IIZZ') if sig=='I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_AC_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = largest_AC_set[1].terms.values()\n",
    "qNos, Pstrs = zip(*list(largest_AC_set[1].terms.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const2 = largest_AC_set[2].terms.values()\n",
    "qNos2, Pstrs2 = zip(*list(largest_AC_set[2].terms.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qNos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_canellations_from_list(P_list, P_active, n_qubits):\n",
    "    \"\"\"\n",
    "    Function gives a score for how many change of basis Pauli operators can obtained for P_active\n",
    "    iterating backwards through P_list. Idea is to use this to re_order terms in SeqRot to maximize\n",
    "    change of basis cancellations\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    P_dict =  dict(tuple(*P_active.terms.keys())) \n",
    "    qNos_active = np.array(list(P_dict.keys()))\n",
    "    Pstrs_active = np.array([P_dict.get(qNo, 'I') for qNo in range(n_qubits)])\n",
    "    \n",
    "    largest_canellation = len(qNos_active)\n",
    "    N_cancellations=0\n",
    "    for P_op in P_list[::-1]: # reverse order\n",
    "        P_comp_dict =  dict(tuple(*P_op.terms.keys())) \n",
    "        Pstrs_comp = np.array([P_comp_dict.get(qNo, 'I') for qNo in range(n_qubits)])\n",
    "        \n",
    "        ind_to_delete=[]\n",
    "        for j, act_ind in enumerate(qNos_active):\n",
    "            if Pstrs_comp[act_ind]== Pstrs_active[act_ind]:\n",
    "                ind_to_delete.append(j)\n",
    "                N_cancellations+=1\n",
    "                \n",
    "            elif Pstrs_comp[act_ind] == 'I':\n",
    "                continue\n",
    "            else:\n",
    "                # case when mismatch!\n",
    "                ind_to_delete.append(j)\n",
    "                # delete term BUT don't add to cancellation counter\n",
    "        \n",
    "        qNos_active = np.delete(qNos_active, ind_to_delete, 0)\n",
    "        \n",
    "    score = N_cancellations/largest_canellation\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermion import QubitOperator\n",
    "P_list = [QubitOperator('X1 X2', 1), QubitOperator('Z0', 1), QubitOperator('Z1 X2 Z4', 1)]\n",
    "\n",
    "P_active = QubitOperator('Z0 Z2', 1)\n",
    "\n",
    "Count_canellations_from_list(P_list, P_active, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def lexicographical_sort_BASIS_MATCH(list_P_ops, n_qubits):\n",
    "    \"\"\"\n",
    "    maximises adjacent single qubit pauli terms in Pauliword list (allowing best change of basis cancellation)\n",
    "    \"\"\"\n",
    "    list_P_ops = deepcopy(list_P_ops)\n",
    "    final_list_size = len(list_P_ops)\n",
    "    \n",
    "    size_of_terms = [(ind, len(list(*op.terms.keys()))) for ind, op in enumerate(list_P_ops)]\n",
    "    selected_ind = min(size_of_terms, key=lambda x:x[1])[0] # get ind of longest term\n",
    "    re_ordered_P_op_list = [list_P_ops.pop(selected_ind)] # first term in longest\n",
    "    \n",
    "#     re_ordered_P_op_list = [list_P_ops.pop(0)] # first term is first thing in list\n",
    "    \n",
    "    while len(re_ordered_P_op_list)<final_list_size:\n",
    "\n",
    "        score_list = [(ind, Count_canellations_from_list(re_ordered_P_op_list, op, n_qubits)) \n",
    "                      for ind, op in enumerate(list_P_ops)]\n",
    "        \n",
    "\n",
    "        selected_ind = max(score_list, key=lambda x:x[1])[0]\n",
    "        re_ordered_P_op_list.append(list_P_ops.pop(selected_ind))\n",
    "\n",
    "    return re_ordered_P_op_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ordered = lexicographical_sort_BASIS_MATCH(largest_AC_set, 5)\n",
    "re_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_basis_cancellation(P_list, P_active, n_qubits):\n",
    "    \"\"\"\n",
    "    Function gives a score for how many change of basis Pauli operators can obtained for P_active\n",
    "    iterating backwards through P_list. Idea is to use this to re_order terms in SeqRot to maximize\n",
    "    change of basis cancellations\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    P_dict =  dict(tuple(*P_active.terms.keys())) \n",
    "    qNos_active = np.array(list(P_dict.keys()))\n",
    "    Pstrs_active = np.array([P_dict.get(qNo, 'I') for qNo in range(n_qubits)])\n",
    "    \n",
    "    largest_canellation = len(qNos_active)\n",
    "    N_cancellations=0\n",
    "    for P_op in P_list:\n",
    "        P_comp_dict =  dict(tuple(*P_op.terms.keys())) \n",
    "        Pstrs_comp = np.array([P_comp_dict.get(qNo, 'I') for qNo in range(n_qubits)])\n",
    "        \n",
    "        ind_to_delete=[]\n",
    "        for j, act_ind in enumerate(qNos_active):\n",
    "            if Pstrs_comp[act_ind]== Pstrs_active[act_ind]:\n",
    "                ind_to_delete.append(j)\n",
    "                N_cancellations+=1\n",
    "                \n",
    "            elif Pstrs_comp[act_ind] == 'I':\n",
    "                continue\n",
    "            else:\n",
    "                # case when mismatch!\n",
    "                ind_to_delete.append(j)\n",
    "                # delete term BUT don't add to cancellation counter\n",
    "        \n",
    "        qNos_active = np.delete(qNos_active, ind_to_delete, 0)\n",
    "        \n",
    "    return N_cancellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_canc=0\n",
    "for ind, op in enumerate(re_ordered[:-1]):\n",
    "    N_canc += Count_basis_cancellation(re_ordered[(ind+1):], op, 5)\n",
    "N_canc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_canellations_from_list(P_list, P_active, n_qubits):\n",
    "    \"\"\"\n",
    "    Function gives a score for how many change of basis Pauli operators can obtained for P_active\n",
    "    iterating backwards through P_list. Idea is to use this to re_order terms in SeqRot to maximize\n",
    "    change of basis cancellations\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    P_dict =  dict(tuple(*P_active.terms.keys())) \n",
    "    qNos_active = np.array(list(P_dict.keys()))\n",
    "    Pstrs_active = np.array([P_dict.get(qNo, 'I') for qNo in range(n_qubits)])\n",
    "    \n",
    "    largest_canellation = len(qNos_active)\n",
    "    N_cancellations=0\n",
    "    for P_op in P_list[::-1]: # reverse order\n",
    "        P_comp_dict =  dict(tuple(*P_op.terms.keys())) \n",
    "        Pstrs_comp = np.array([P_comp_dict.get(qNo, 'I') for qNo in range(n_qubits)])\n",
    "        \n",
    "        ind_to_delete=[]\n",
    "        for j, act_ind in enumerate(qNos_active):\n",
    "            if Pstrs_comp[act_ind]== Pstrs_active[act_ind]:\n",
    "                ind_to_delete.append(j)\n",
    "                N_cancellations+=1\n",
    "                \n",
    "            elif Pstrs_comp[act_ind] == 'I':\n",
    "                continue\n",
    "            else:\n",
    "                # case when mismatch!\n",
    "                ind_to_delete.append(j)\n",
    "                # delete term BUT don't add to cancellation counter\n",
    "        \n",
    "        qNos_active = np.delete(qNos_active, ind_to_delete, 0)\n",
    "        \n",
    "    score = N_cancellations/largest_canellation\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " max(out, key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.intersect1d(qNos, qNos2)\n",
    "test2 = np.delete(test, 1, 0)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_dict =  dict(tuple(*largest_AC_set[1].terms.keys())) \n",
    "max_qubits=5\n",
    "arr = [P_dict.get(qNo, 'I') for qNo in range(max_qubits)]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_AC_set_copy = deepcopy(largest_AC_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_order = [largest_AC_set_copy.pop(0)]\n",
    "\n",
    "while len(running_order)< len(largest_AC_set):\n",
    "    for term in largest_AC_set_copy:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quchem.Unitary_Partitioning.Graph import Vector_QubitHamiltonian\n",
    "from functools import reduce\n",
    "from openfermion.utils import count_qubits\n",
    "\n",
    "list_P_ops = largest_AC_set\n",
    "\n",
    "fullOp = reduce(lambda Op1, Op2: Op1+Op2, list_P_ops)\n",
    "max_qubits = count_qubits(fullOp)\n",
    "\n",
    "Hamilt_vector = Vector_QubitHamiltonian(fullOp, max_qubits)\n",
    "binary_matrix =  Hamilt_vector.binary_mat.toarray()\n",
    "\n",
    "print(binary_matrix)\n",
    "list(fullOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = binary_matrix[0].copy().reshape(1, binary_matrix.shape[1])\n",
    "binary_matrix =np.delete(binary_matrix, 0, 0)\n",
    "\n",
    "while binary_matrix.shape[0]>0:\n",
    "    score_list=[]\n",
    "    for P_vec in binary_matrix:\n",
    "        active_X_ind = np.where(P_vec[:max_qubits]>0)[0]\n",
    "        active_Z_ind = np.where(P_vec[max_qubits:]>0)[0]\n",
    "        max_cancellations = len(np.where((P_vec[:max_qubits]+P_vec[max_qubits:])>0))\n",
    "        n_canellations=0\n",
    "        for rev_ind in list(range(new_order.shape[0]-1, -1, -1)):\n",
    "            P_last = new_order[rev_ind]\n",
    "            similarity += sum((P_vec==P_last).astype(int))\n",
    "            \n",
    "            I_locations = np.intersect1d(np.where(P_last[:max_qubits]==0)[0], np.where(P_last[max_qubits:]==0)[0])\n",
    "            ind_sympletic = np.hstack((I_locations, max_qubits+I_locations))\n",
    "            \n",
    "            empty = np.zeros_like(P_vec)\n",
    "            empty[ind_sympletic] = P_vec[ind_sympletic]\n",
    "            P_vec = empty\n",
    "            \n",
    "        score_list.append(similarity)\n",
    "    \n",
    "    print(score_list)\n",
    "    largest_ind = score_list.index(max(score_list))\n",
    "    new_order = np.vstack((new_order, binary_matrix[largest_ind]))\n",
    "    binary_matrix =np.delete(binary_matrix, largest_ind, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_active = largest_AC_set[4]\n",
    "print(P_active)\n",
    "Q_Nos, P_strings = zip(*list(*P_active.terms.keys()))\n",
    "[(Q_Nos[ind], Q_Nos[ind+1]) for ind, i in enumerate(Q_Nos[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set([i for tup in xxx for i in tup]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_CNOT_cancellation(P_list, P_active, n_qubits):\n",
    "    \"\"\"\n",
    "    Function gives a score for how many change of basis Pauli operators can obtained for P_active\n",
    "    iterating backwards through P_list. Idea is to use this to re_order terms in SeqRot to maximize\n",
    "    change of basis cancellations\n",
    "    \n",
    "    \"\"\"\n",
    "    P_list = deepcopy(P_list)\n",
    "    \n",
    "#     P_dict =  dict(tuple(*P_active.terms.keys())) \n",
    "    Q_Nos, P_strings = zip(*list(*P_active.terms.keys()))\n",
    "    \n",
    "    open_CNOT_active = [(Q_Nos[ind], Q_Nos[ind+1]) for ind, i in enumerate(Q_Nos[:-1])]\n",
    "    \n",
    "    P_dict =  dict(tuple(*P_active.terms.keys())) \n",
    "    Pstrs_active = np.array([P_dict.get(qNo, 'I') for qNo in range(n_qubits)], dtype=object)\n",
    "    \n",
    "    \n",
    "    largest_canellation = len(Q_Nos)-1\n",
    "    \n",
    "    if largest_canellation ==0:\n",
    "        # single qubit case (no CNOT cancellations possible)\n",
    "        return 0\n",
    "    \n",
    "    running_CNOT_terms =[]\n",
    "    list_Pstrs_comp = []\n",
    "    seen_qubits = {}\n",
    "    for com_ind, P_op in enumerate(P_list[::-1]):\n",
    "            \n",
    "        \n",
    "        Q_Nos_compare, P_strings_comp = zip(*list(*P_op.terms.keys()))\n",
    "        Q_Nos_comp=[]\n",
    "        for qNo in Q_Nos_compare:\n",
    "            if qNo in seen_qubits:\n",
    "                break\n",
    "            else:\n",
    "                Q_Nos_comp.append(qNo)\n",
    "        \n",
    "        open_CNOT_comp = [(Q_Nos_comp[ind], Q_Nos_comp[ind+1]) for ind, i in enumerate(Q_Nos_comp[:-1])]\n",
    "        running_CNOT_terms.append(open_CNOT_comp)\n",
    "        \n",
    "        seen_qubits = set([*list(seen_qubits), *Q_Nos_comp])\n",
    "        \n",
    "        P_dict_comp =  dict(tuple(*P_op.terms.keys())) \n",
    "        list_Pstrs_comp.append(np.array([P_dict_comp.get(qNo, 'I') for qNo in range(n_qubits)], dtype=object))\n",
    "    \n",
    "    N_cancellations=0\n",
    "    for i, CNOT_term_list in enumerate(running_CNOT_terms):\n",
    "        for active_tup, comp_tup in zip(open_CNOT_active, CNOT_term_list):\n",
    "            Pstrs_comp = list_Pstrs_comp[i]\n",
    "            if (active_tup==comp_tup) and (Pstrs_active[np.array(active_tup)]==Pstrs_comp[np.array(comp_tup)]).all():\n",
    "                # checks for same indices AND same change of basis!\n",
    "                N_cancellations+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    score = N_cancellations/largest_canellation\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_list = [QubitOperator('Y1 Z3 Y4 ', 1), QubitOperator('Y0 Z1 Z3 Y4', 1), QubitOperator('Y0 Z1 Z2 Y3', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_CNOT_cancellation(P_list[:-1], P_list[-1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def lexicographical_sort_CNOT_cancel(list_P_ops, n_qubits):\n",
    "    \"\"\"\n",
    "    maximises adjacent single qubit pauli terms in Pauliword list (allowing best change of basis cancellation)\n",
    "    \"\"\"\n",
    "    list_P_ops = deepcopy(list_P_ops)\n",
    "    final_list_size = len(list_P_ops)\n",
    "    \n",
    "    size_of_terms = [(ind, len(list(*op.terms.keys()))) for ind, op in enumerate(list_P_ops)]\n",
    "    selected_ind = max(size_of_terms, key=lambda x:x[1])[0] # get ind of longest term\n",
    "    re_ordered_P_op_list = [list_P_ops.pop(selected_ind)] # first term in longest\n",
    "    \n",
    "#     re_ordered_P_op_list = [list_P_ops.pop(0)] # first term is first thing in list\n",
    "    \n",
    "    while len(re_ordered_P_op_list)<final_list_size:\n",
    "\n",
    "        score_list = [(ind, Count_CNOT_cancellation(re_ordered_P_op_list, op, n_qubits)) \n",
    "                      for ind, op in enumerate(list_P_ops)]\n",
    "        \n",
    "        if sum(score_val for _, score_val in score_list)==0:\n",
    "            # no CNOT cancel possible\n",
    "            # therefore maximize basis cancel\n",
    "            print(score_list)\n",
    "            score_list = [(ind, Count_canellations_from_list(re_ordered_P_op_list, op, n_qubits)) \n",
    "                      for ind, op in enumerate(list_P_ops)]\n",
    "            \n",
    "        selected_ind = max(score_list, key=lambda x:x[1])[0]\n",
    "        re_ordered_P_op_list.append(list_P_ops.pop(selected_ind))\n",
    "\n",
    "    return re_ordered_P_op_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ordered = lexicographical_sort_BASIS_MATCH(largest_AC_set, 5)\n",
    "re_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ordered_CNOT_cancel = lexicographical_sort_CNOT_cancel(largest_AC_set, 5)\n",
    "re_ordered_CNOT_cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_AC_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_RS_circuit_tiket, Ps, gamma_l = Auto_Build_R_SeqRot_Q_circuit_tiket_Reduced(re_ordered_CNOT_cancel,\n",
    "                                                      N_qubits, \n",
    "                                                      check_reduction_lin_alg=True, \n",
    "                                                      atol=1e-8, rtol=1e-05, \n",
    "                                                      check_circuit=True, \n",
    "                                                      maximise_CNOT_reduction=True)\n",
    "full_RS_circuit_tiket\n",
    "print(count_circuit_gates(full_RS_circuit_tiket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_AC_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_RS_circuit_tiket, Ps, gamma_l = Auto_Build_R_SeqRot_Q_circuit_tiket_Reduced(re_ordered,\n",
    "                                                      N_qubits, \n",
    "                                                      check_reduction_lin_alg=True, \n",
    "                                                      atol=1e-8, rtol=1e-05, \n",
    "                                                      check_circuit=True, \n",
    "                                                      maximise_CNOT_reduction=True)\n",
    "full_RS_circuit_tiket\n",
    "print(count_circuit_gates(full_RS_circuit_tiket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_RS_circuit_tiket, Ps, gamma_l = Auto_Build_R_SeqRot_Q_circuit_tiket_Reduced(largest_AC_set,\n",
    "                                                      N_qubits, \n",
    "                                                      check_reduction_lin_alg=True, \n",
    "                                                      atol=1e-8, rtol=1e-05, \n",
    "                                                      check_circuit=True, \n",
    "                                                      maximise_CNOT_reduction=True)\n",
    "full_RS_circuit_tiket\n",
    "print(count_circuit_gates(full_RS_circuit_tiket))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
